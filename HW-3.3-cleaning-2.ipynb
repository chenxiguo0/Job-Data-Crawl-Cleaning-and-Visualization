{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "format:\n",
    "    html:\n",
    "        embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning: Part-2 \n",
    "\n",
    "The goal here is exactly the same as `HW-3.2-cleaning-1.ipynb`, except this time we will repeat the exercise but by leveraging LLM APIs and prompt engineering to stream line the cleaning process. \n",
    "\n",
    "Essentially, our job is to write an LLM wrapper to clean the job descriptions. \n",
    "\n",
    "We can use any LLM API that you want, and we can use any prompt engineering techniques. \n",
    "\n",
    "\n",
    "Here is an example of how to use OpenAI's API:\n",
    "\n",
    "[https://jfh.georgetown.domains/centralized-lecture-content/content/computer-science/general-concepts/openAI-API-example/notes.html](https://jfh.georgetown.domains/centralized-lecture-content/content/computer-science/general-concepts/openAI-API-example/notes.html)\n",
    "\n",
    "There are also various LLM APIs that we can wrap around to get partial access. Do some googling and find a tool that seems like it will fit our needs.  \n",
    "\n",
    "* [https://ai.google.dev/gemini-api/docs/quickstart?lang=python](https://ai.google.dev/gemini-api/docs/quickstart?lang=python)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_job(job):\n",
    "    job_fields=\"\"\"\n",
    "    {{\n",
    "        \"job_title\": \"\",\n",
    "        \"company_name\": \"\",\n",
    "        \"sector\": \"\",\n",
    "        \"location\": \"\",\n",
    "        \"job_type\": \"\",\n",
    "        \"salary_range\": \"\",\n",
    "        \"experience_level\": \"\",\n",
    "        \"education_requirements\": \"\",\n",
    "        \"required_skills\": \"\",\n",
    "        \"responsibilities\": \"\",\n",
    "        \"years_experience\": \"\",\n",
    "        \"benefits\": \"\",\n",
    "        \"work_mode\": \"\",\n",
    "        \"posting_date\": \"\",\n",
    "        \"job_description_length\": \"\",\n",
    "        \"required_certifications\": \"\",\n",
    "        \"team_size\": \"\",\n",
    "        \"company_size\": \"\",\n",
    "        \"posting_platform\": \"\",\n",
    "        \"company_culture\": \"\",\n",
    "        \"visa_sponsorship\": \"\",\n",
    "        \"working_hours\": \"\",\n",
    "        \"language_requirements\": \"\",\n",
    "        \"travel_requirements\": \"\",\n",
    "        \"collaboration_tools\": \"\",\n",
    "        \"reporting_structure\": \"\",\n",
    "        \"learning_opportunities\": \"\",\n",
    "        \"stock_options\": \"\",\n",
    "        \"soft_skills\": \"\",\n",
    "        \"perks\": \"\",\n",
    "        \"job_id\": \"\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f'''Here is some job data loaded from a json file, please analyze this job listing and extract the following information in JSON format. \n",
    "    If a field is not available, use null. Be concise and factual:\n",
    "    {job_fields}\n",
    "\n",
    "    Job Data:\n",
    "    {json.dumps(job,indent=2)}\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that extracts and cleans job posting data. Return only the JSON object with the extracted information.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=1000)\n",
    "        \n",
    "        cleaned_data = json.loads(response.choices[0].message.content)\n",
    "        return cleaned_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing job: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing job: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_data_llm(crawled_data):\n",
    "    all_cleaned_jobs = []\n",
    "\n",
    "    jobs_results = []\n",
    "    for crawled_unit in crawled_data:\n",
    "        new_unit = crawled_unit['results'].get('jobs_results',[])\n",
    "        jobs_results.extend(new_unit)\n",
    "\n",
    "    for job in tqdm(jobs_results, desc=\"Processing jobs\"):\n",
    "        cleaned_job = process_job(job)\n",
    "        if cleaned_job:\n",
    "            all_cleaned_jobs.append(cleaned_job)\n",
    "        time.sleep(0.1)  \n",
    "    \n",
    "    return all_cleaned_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(cleaned_data, output_file):\n",
    "    df = pd.DataFrame(cleaned_data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs:   4%|▍         | 37/847 [03:51<1:47:45,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing job: Unterminated string starting at: line 32 column 15 (char 1709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs:  22%|██▏       | 186/847 [20:28<1:22:11,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing job: Unterminated string starting at: line 32 column 15 (char 1528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs:  85%|████████▍ | 717/847 [1:19:32<16:35,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing job: Unterminated string starting at: line 32 column 15 (char 1344)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs:  86%|████████▋ | 732/847 [1:21:10<14:04,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing job: Unterminated string starting at: line 32 column 15 (char 2251)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs:  87%|████████▋ | 738/847 [1:21:56<14:52,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing job: Unterminated string starting at: line 32 column 15 (char 2361)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing jobs: 100%|██████████| 847/847 [1:37:31<00:00,  6.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           job_title     company_name  \\\n",
      "0                       Data Scientist, Data Science  Cardinal Health   \n",
      "1             Usability Researcher 2- Data Scientist    Jobs via Dice   \n",
      "2  Senior Data Scientist – Financial Crimes and T...             USAA   \n",
      "3                                Data Scientist, R&D      Eight Sleep   \n",
      "4                       Data Scientist I B - GBS IND  Bank of America   \n",
      "\n",
      "               sector                  location   job_type  \\\n",
      "0                None  United States (+1 other)  Full-time   \n",
      "1          Technology                  Anywhere  Full-time   \n",
      "2  Financial Services      Colorado Springs, CO  Full-time   \n",
      "3   Consumer Wellness                  Anywhere  Full-time   \n",
      "4             Finance                  Anywhere  Full-time   \n",
      "\n",
      "          salary_range                                   experience_level  \\\n",
      "0   $93,500 - $133,600                                           3+ years   \n",
      "1                 None                                   Mid-Senior level   \n",
      "2  $138,230 - $248,810  6 years of experience in predictive analytics ...   \n",
      "3                 None                                           4+ years   \n",
      "4                 None                                        4 - 6 Years   \n",
      "\n",
      "                              education_requirements  \\\n",
      "0  Advanced degree in Statistics or related field...   \n",
      "1                                               None   \n",
      "2  Bachelor’s degree in mathematics, computer sci...   \n",
      "3  Bachelor's degree in Data Science, Statistics,...   \n",
      "4  B.E. / B. Tech/M.E. /M. Tech, Graduate degree ...   \n",
      "\n",
      "                                     required_skills  \\\n",
      "0  Strong programming experience with R and/or Py...   \n",
      "1  Data Domain/Data science, Research skills, UX ...   \n",
      "2  Machine learning, statistical analysis, Python...   \n",
      "3  Python, R, SQL, Github, data visualization too...   \n",
      "4    Python, SQL, PySpark, Oracle, Hadoop, JIRA, Git   \n",
      "\n",
      "                                    responsibilities  ...  \\\n",
      "0  Develop algorithms, predictive models, collabo...  ...   \n",
      "1  Conduct qualitative and quantitative research ...  ...   \n",
      "2  Translate business problems into applied stati...  ...   \n",
      "3  Improve core intelligent features, develop use...  ...   \n",
      "4  Adhering to software standards, developing mod...  ...   \n",
      "\n",
      "  language_requirements         travel_requirements collaboration_tools  \\\n",
      "0                  None                        None                None   \n",
      "1                  None                        None                None   \n",
      "2                  None  Occasional business travel                None   \n",
      "3                  None                        None                None   \n",
      "4                  None                        None           JIRA, Git   \n",
      "\n",
      "  reporting_structure                             learning_opportunities  \\\n",
      "0                None                                               None   \n",
      "1                None                                               None   \n",
      "2                None                   Continuing education, mentorship   \n",
      "3                None  Fantastic learning opportunities, achievements...   \n",
      "4                None   Opportunities to learn, grow, and make an impact   \n",
      "\n",
      "  stock_options                                        soft_skills  \\\n",
      "0          None               Clear communication, problem-solving   \n",
      "1          None                  Communication, project management   \n",
      "2          None                                               None   \n",
      "3          None  Clear communication, attention to detail, adap...   \n",
      "4          None         Analytical, problem-solving, communication   \n",
      "\n",
      "                                               perks  \\\n",
      "0                                               None   \n",
      "1                                               None   \n",
      "2  Paid time off, health insurance, dental insurance   \n",
      "3  Receive a Pod, health insurance, dental insura...   \n",
      "4                                               None   \n",
      "\n",
      "                                              job_id  via  \n",
      "0  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCwgRGF0YS...  NaN  \n",
      "1  eyJqb2JfdGl0bGUiOiJVc2FiaWxpdHkgUmVzZWFyY2hlci...  NaN  \n",
      "2  eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBTY2llbnRpc3...  NaN  \n",
      "3  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCwgUlx1MD...  NaN  \n",
      "4  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBJIEIgLS...  NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with open('googlejobs_alltitles_2024-11-05_22-34-20.json', 'r') as file:\n",
    "        crawled_data = json.load(file)\n",
    "\n",
    "    cleaned_data = clean_job_data_llm(crawled_data)\n",
    "    \n",
    "    output_file = 'data/processed-jobs-2.csv'\n",
    "    df = save_data(cleaned_data, output_file)\n",
    "\n",
    "    print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
