{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "format:\n",
    "    html:\n",
    "        embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning: Part-1: \n",
    "\n",
    "The goal now is to post process the job descriptions you collected in the Crawl\n",
    "\n",
    "In this section you MUST do it manually using traditional data-science cleaning and parsing skills, i.e. without use of ANY LLM tools or wrappers.\n",
    "\n",
    "The unit of analysis in this case is \"job\" \n",
    "\n",
    "Your job is to write a cleaning script to Parse the Crawl results and create a data-frame which will be saved to `data/processed-jobs-1.csv`, this data-frame will be used for later EDA. \n",
    "\n",
    "\n",
    "You should try to extract as many features as possible, here a possible suggestions. \n",
    "\n",
    "These features can provide a comprehensive overview when analyzing job postings for trends, patterns, and insights.\n",
    "\n",
    "You will almost certainly not be able to extract all of these features, but do your best to make the most detailed data set that you can. You can also ADD more features to this list if they come to mind.\n",
    "\n",
    "- **Job Title**\n",
    "- **Company Name**\n",
    "- **Sector/Industry**\n",
    "- **Location** (City, State, Country)\n",
    "- **Job Type** (Full-time, Part-time, Contract, Internship)\n",
    "- **Salary** (Range or Exact)\n",
    "- **Experience Level** (Entry-level, Mid-level, Senior-level)\n",
    "- **Education Requirements** (Degree, Major, Certifications)\n",
    "- **Skills/Technologies Required** (e.g., Python, SQL, Machine Learning, Cloud)\n",
    "- **Job Responsibilities/Duties**\n",
    "- **Required Years of Experience**\n",
    "- **Benefits** (Health insurance, Retirement plans, Paid time off)\n",
    "- **Remote Work Options** (Remote, Hybrid, On-site)\n",
    "- **Application Deadline**\n",
    "- **Job Posting Date**\n",
    "- **Job Description Length** (Number of words or characters)\n",
    "- **Keywords/Frequency of Terms**\n",
    "- **Certifications Required or Preferred** (e.g., AWS Certified, PMP)\n",
    "- **Team Size** (If mentioned)\n",
    "- **Company Size** (Small, Medium, Large)\n",
    "- **Company Reputation/Ranking** (If available)\n",
    "- **Job Posting Platform** (Where the job was posted, e.g., LinkedIn, Indeed)\n",
    "- **Company Values or Culture** (Diversity, Innovation, Sustainability)\n",
    "- **Visa Sponsorship Availability**\n",
    "- **Interview Process Information** (If mentioned)\n",
    "- **Expected Start Date**\n",
    "- **Job Posting Expiry Date**\n",
    "- **Gender Diversity Language** (If any)\n",
    "- **Working Hours/Shift Type** (Day shift, Night shift, Flexible hours)\n",
    "- **Required Language Skills**\n",
    "- **Job Location Proximity to Major Cities** (If provided)\n",
    "- **Travel Requirements** (Percentage or Frequency)\n",
    "- **Team Collaboration Tools Mentioned** (Slack, Zoom, etc.)\n",
    "- **Reporting Line** (e.g., Reports to Senior Manager)\n",
    "- **Job Benefits Related to Learning & Development** (e.g., Courses, Training)\n",
    "- **Company Stock Options** (If offered)\n",
    "- **Required Soft Skills** (e.g., Communication, Leadership)\n",
    "- **Company Perks** (Gym membership, Free meals, Company car)\n",
    "- **Job Posting ID or Reference Number**\n",
    "\n",
    "\n",
    "While cleaning try to address the following as best you can\n",
    "\n",
    "- **Missing Data**: Identify missing or null values in features like salary, company name, or location.\n",
    "- **Duplicates**: Check for duplicate job listings or job descriptions.\n",
    "- **Inconsistent Formatting**: Ensure consistency in categorical variables (e.g., job titles, location formats).\n",
    "- **Data Type Validation**: Ensure each feature has the appropriate data type (e.g., salary as numeric, dates as datetime).\n",
    "- **Outliers**: Detect outliers in salary, years of experience, or job description length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "with open ('googlejobs_alltitles_2024-11-05_22-34-20.json','r') as file:\n",
    "    crawled_data = json.load(file)\n",
    "\n",
    "jobs_results = []\n",
    "for crawled_unit in crawled_data[0:89]:\n",
    "    new_unit = crawled_unit['results']['jobs_results']\n",
    "    jobs_results.extend(new_unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary(description):\n",
    "    salary_match = re.search(r'(\\$[\\d,]+(?:\\s*-\\s*\\$[\\d,]+)?)', description)\n",
    "    return salary_match.group(0) if salary_match else np.nan\n",
    "\n",
    "def extract_experience_level(description):\n",
    "    if 'entry' in description.lower():\n",
    "        return 'Entry-level'\n",
    "    elif 'senior' in description.lower():\n",
    "        return 'Senior-level'\n",
    "    elif 'mid' in description.lower():\n",
    "        return 'Mid-level'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def extract_skills(description):\n",
    "    skills = ['python', 'r', 'sql', 'machine learning', 'deep learning', 'ai', 'cloud', 'statistics']\n",
    "    found_skills = [skill for skill in skills if skill.lower() in description.lower()]\n",
    "    return ', '.join(found_skills) if found_skills else np.nan\n",
    "\n",
    "def extract_responsibilities(job_highlights):\n",
    "    responsibilities = []\n",
    "    for highlight in job_highlights:\n",
    "        if highlight['title'].lower() == 'responsibilities':\n",
    "            responsibilities.extend(highlight['items'])\n",
    "    return ', '.join(responsibilities) if responsibilities else np.nan\n",
    "\n",
    "def extract_benefits(job_highlights):\n",
    "    benefits = []\n",
    "    for highlight in job_highlights:\n",
    "        if highlight['title'].lower() == 'benefits':\n",
    "            benefits.extend(highlight['items'])\n",
    "    return ', '.join(benefits) if benefits else np.nan\n",
    "\n",
    "def extract_posting_date(posted_at):\n",
    "    if not posted_at:\n",
    "        return np.nan\n",
    "        \n",
    "    try:\n",
    "        if isinstance(posted_at, str):\n",
    "            if 'day' in posted_at.lower():\n",
    "                days = int(re.search(r'(\\d+)', posted_at).group(1))\n",
    "                return (datetime.now() - pd.Timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "            elif 'hour' in posted_at.lower():\n",
    "                hours = int(re.search(r'(\\d+)', posted_at).group(1))\n",
    "                return (datetime.now() - pd.Timedelta(hours=hours)).strftime('%Y-%m-%d')\n",
    "            elif 'minute' in posted_at.lower():\n",
    "                minutes = int(re.search(r'(\\d+)', posted_at).group(1))\n",
    "                return (datetime.now() - pd.Timedelta(minutes=minutes)).strftime('%Y-%m-%d')\n",
    "        return np.nan\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date: {posted_at}, Error: {str(e)}\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_data(jobs_results):\n",
    "    job_list = []\n",
    "\n",
    "    for job in jobs_results:\n",
    "        job_unit = {}\n",
    "        \n",
    "        detected_extensions = job.get('detected_extensions', {})\n",
    "\n",
    "        job_unit['Job Title'] = job.get('title', '').strip()\n",
    "        job_unit['Company Name'] = job.get('company_name', '').strip()\n",
    "        job_unit['Location'] = job.get('location', '').strip()\n",
    "        job_unit['Job Type'] = job.get('detected_extensions', {}).get('schedule_type', '').strip()\n",
    "        job_unit['Salary'] = extract_salary(job.get('description', ''))\n",
    "        job_unit['Experience Level'] = extract_experience_level(job.get('description', ''))\n",
    "        job_unit['Skills/Technologies Required'] = extract_skills(job.get('description', ''))\n",
    "        job_unit['Benefits'] = extract_benefits(job.get('job_highlights', []))\n",
    "        job_unit['Job Responsibilities/Duties'] = extract_responsibilities(job.get('job_highlights', []))\n",
    "        job_unit['Job Posting Date'] = extract_posting_date(detected_extensions.get('posted_at', ''))\n",
    "        job_unit['Job Description Length'] = len(job.get('description', ''))\n",
    "        job_unit['Job Posting Platform'] = ', '.join([apply_option['title'] for apply_option in job.get('apply_options', [])])\n",
    "        job_unit['Job Posting ID'] = job.get('job_id', '')\n",
    "\n",
    "        job_list.append(job_unit)\n",
    "\n",
    "    df = pd.DataFrame(job_list)\n",
    "\n",
    "    df['Salary'].replace('', np.nan, inplace=True)\n",
    "    df['Experience Level'].replace('', np.nan, inplace=True)\n",
    "    df['Skills/Technologies Required'].replace('', np.nan, inplace=True)\n",
    "    df['Job Responsibilities/Duties'].replace('', np.nan, inplace=True)\n",
    "    df['Job Posting Date'].replace('', np.nan, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Job Title     Company Name  \\\n",
      "0                       Data Scientist, Data Science  Cardinal Health   \n",
      "1             Usability Researcher 2- Data Scientist    Jobs via Dice   \n",
      "2  Senior Data Scientist – Financial Crimes and T...             USAA   \n",
      "3                                Data Scientist, R&D      Eight Sleep   \n",
      "4                       Data Scientist I B - GBS IND  Bank of America   \n",
      "\n",
      "                   Location   Job Type               Salary Experience Level  \\\n",
      "0  United States (+1 other)  Full-time   $93,500 - $133,600     Senior-level   \n",
      "1                  Anywhere  Full-time                  NaN     Senior-level   \n",
      "2      Colorado Springs, CO  Full-time  $138,230 - $248,810     Senior-level   \n",
      "3                  Anywhere  Full-time                  NaN              NaN   \n",
      "4                  Anywhere  Full-time                  NaN              NaN   \n",
      "\n",
      "                        Skills/Technologies Required  \\\n",
      "0  python, r, machine learning, deep learning, ai...   \n",
      "1                                       r, ai, cloud   \n",
      "2  python, r, sql, machine learning, ai, cloud, s...   \n",
      "3  python, r, sql, machine learning, deep learnin...   \n",
      "4                                 python, r, sql, ai   \n",
      "\n",
      "                                            Benefits  \\\n",
      "0  Anticipated salary range: $93,500 - $133,600, ...   \n",
      "1  Employee pay is based on factors like relevant...   \n",
      "2  This position can work remotely in the contine...   \n",
      "3  Equitable compensation and continuous equity i...   \n",
      "4                                                NaN   \n",
      "\n",
      "                         Job Responsibilities/Duties Job Posting Date  \\\n",
      "0  The Data Science Advisor position will report ...       2024-11-04   \n",
      "1  Kforce has a client in Redmond, WA that is see...       2024-11-08   \n",
      "2  As a dedicated Senior Data Scientist, you will...       2024-11-08   \n",
      "3  Our employees report working up to 60 hours pe...              NaN   \n",
      "4                                                NaN       2024-11-07   \n",
      "\n",
      "   Job Description Length                               Job Posting Platform  \\\n",
      "0                    3551  Cardinal Health, Workday, ZipRecruiter, Linked...   \n",
      "1                    4177  LinkedIn, Dice, Monster, Jobs And Talents In A...   \n",
      "2                    9221                                LinkedIn, Talentify   \n",
      "3                    6142        Jobs, LinkedIn, Jobgether, Adzuna, Jobilize   \n",
      "4                    5485  Leadership Triangle Job, Tech Titans Job Board...   \n",
      "\n",
      "                                      Job Posting ID  \n",
      "0  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCwgRGF0YS...  \n",
      "1  eyJqb2JfdGl0bGUiOiJVc2FiaWxpdHkgUmVzZWFyY2hlci...  \n",
      "2  eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBTY2llbnRpc3...  \n",
      "3  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCwgUlx1MD...  \n",
      "4  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBJIEIgLS...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/dvn1kl9j1_74vy3jnlj_hw580000gn/T/ipykernel_75563/1711049949.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Salary'].replace('', np.nan, inplace=True)\n",
      "/var/folders/_7/dvn1kl9j1_74vy3jnlj_hw580000gn/T/ipykernel_75563/1711049949.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Experience Level'].replace('', np.nan, inplace=True)\n",
      "/var/folders/_7/dvn1kl9j1_74vy3jnlj_hw580000gn/T/ipykernel_75563/1711049949.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Skills/Technologies Required'].replace('', np.nan, inplace=True)\n",
      "/var/folders/_7/dvn1kl9j1_74vy3jnlj_hw580000gn/T/ipykernel_75563/1711049949.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Job Responsibilities/Duties'].replace('', np.nan, inplace=True)\n",
      "/var/folders/_7/dvn1kl9j1_74vy3jnlj_hw580000gn/T/ipykernel_75563/1711049949.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Job Posting Date'].replace('', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = clean_job_data(jobs_results)\n",
    "cleaned_data.to_csv('data/processed-jobs-1.csv', index=False)\n",
    "print(cleaned_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
